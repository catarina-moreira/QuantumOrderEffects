{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Quantum vs Markov Random Walk Models of Judgements Mwasured by Rating Scale\n",
    "\n",
    "**Authors: Z. Wang and J. Busemeyer**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import expm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Paper: AB Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypothesis:** The process of switching from a self's own perspective to another;s perspective requires a conginitive shift to imagine what the other person is thinking. This can lead to **incompatibility** of mental states, which generates order effects. A quantum model would be better to model this type of scenario than a classical model. This paper investigates the application of a quantum random walk vs a Markov random walk in rating the effectiveness of public service announcements (PSA) from two perspectives: the self perspective and the other perpective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Random Walk\n",
    "\n",
    "The Markov random walk updates the probabilities of an initial vector E using a transition matrix T that evolves through time *t*. It is defined in the following way:\n",
    "\n",
    "$$ pr_s = e^{t K_s} ~~~~ pr_o = e^{t K_o} $$\n",
    "\n",
    "where $K_s$ and $K_o$ represent the intensity matrices. The intensity matrix describes how the evoltion of the process is conducted. The authors defined an intensity matrix for both the *self* and the *other* perspectives of the participants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining initial_state\n",
    "def initial_state( rating, dims, base ):\n",
    "    E0 = np.zeros(dims)\n",
    "\n",
    "    rating_inter = [rating*base - base+1, rating*base]\n",
    "    \n",
    "    # in python, indexes start in zero, so we need to adjust the interval\n",
    "    N =  rating_inter[1] - (rating_inter[0]-1)\n",
    "    E0[rating_inter[0]-1:rating_inter[1]] = 1/N\n",
    "\n",
    "    return E0\n",
    "\n",
    "# defining the intensity matrix\n",
    "def intensity_mat( alpha, beta, dims ):\n",
    "    k = np.zeros((dims, dims))\n",
    "    \n",
    "    # set diagonal to -(alpha + beta)\n",
    "    np.fill_diagonal(k, -(alpha + beta))\n",
    "\n",
    "    # set upper main diagonal to alpha\n",
    "    m_alpha = np.diag(np.ones(dims-1)*alpha, 1)\n",
    "    # set lower main diagonal to beta\n",
    "    m_beta = np.diag(np.ones(dims-1)*beta, -1)\n",
    "\n",
    "    return k + m_alpha + m_beta\n",
    "\n",
    "# defining the transition matrix\n",
    "def transition_matrix( alpha, beta, t, dims ):\n",
    "    K = intensity_mat( alpha, beta, dims )\n",
    "    T = expm( t*K)\n",
    "    return T\n",
    "\n",
    "# defining projectors based on ratings\n",
    "def projection_mat( rating, dims, base ):\n",
    "    M = np.zeros((Ndim, Ndim))\n",
    "\n",
    "    rating_inter = [rating*base - base+1, rating*base]\n",
    "    \n",
    "    diag_vec = np.zeros(dims)\n",
    "    # in python, indexes start in zero, so we need to adjust the interval\n",
    "    diag_vec[rating_inter[0]-1:rating_inter[1]] = 1\n",
    "    np.fill_diagonal(M, diag_vec)\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_projections(Ndim, base, alpha_s, alpha_o, beta_s, beta_o, t, rating_s, rating_o, order):\n",
    "    rating_init = int( np.floor(base/2) )\n",
    "\n",
    "    E0 = initial_state( rating_init, Ndim, base)\n",
    "    Ts = transition_matrix( alpha_s , beta_s, t, Ndim )\n",
    "    To = transition_matrix( alpha_o , beta_o, t, Ndim )\n",
    "\n",
    "    Ms = projection_mat( rating_s, Ndim, base )\n",
    "    Mo = projection_mat( rating_o, Ndim, base )\n",
    "\n",
    "    L = np.ones(Ndim)\n",
    "    if order == 1:\n",
    "        prob = np.matmul(L, np.matmul(Mo, np.matmul(To, np.matmul(Ms, np.matmul(Ts,E0)))))\n",
    "    else:\n",
    "        prob = np.matmul(L, np.matmul(Ms, np.matmul(Ts, np.matmul(Mo, np.matmul(To,E0)))))\n",
    "\n",
    "    return prob\n",
    "\n",
    "def run_experiment(Ndim, base, alpha_s, alpha_o, beta_s, beta_o, t, rating_in, order):\n",
    "    probs = []\n",
    "    for rating in range(1, 10):\n",
    "        prob = run_projections(Ndim, base, alpha_s, alpha_o, beta_s, beta_o, t, rating_in, rating, order)\n",
    "        # prob = round(prob, 4)\n",
    "        probs.append(prob)\n",
    "        \n",
    "    probs_norm = probs / np.sum(probs)\n",
    "    print(\"Normalised Probabilities\")\n",
    "    for p in range(1, len(probs_norm) + 1):\n",
    "        if order == 1:\n",
    "            print(f\"Pr( Other Rat = %d | Self Rat = %d ) =  %.6f\" %(p, rating_in, probs_norm[p-1]))\n",
    "        else:\n",
    "            print(f\"Pr( Self Rat = %d | Other Rat = %d ) =  %.6f\" %(p, rating_in, probs_norm[p-1]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised Probabilities\n",
      "Pr( Other Rat = 1 | Self Rat = 1 ) =  0.014042\n",
      "Pr( Other Rat = 2 | Self Rat = 1 ) =  0.640635\n",
      "Pr( Other Rat = 3 | Self Rat = 1 ) =  0.342315\n",
      "Pr( Other Rat = 4 | Self Rat = 1 ) =  0.003008\n",
      "Pr( Other Rat = 5 | Self Rat = 1 ) =  0.000001\n",
      "Pr( Other Rat = 6 | Self Rat = 1 ) =  0.000000\n",
      "Pr( Other Rat = 7 | Self Rat = 1 ) =  0.000000\n",
      "Pr( Other Rat = 8 | Self Rat = 1 ) =  0.000000\n",
      "Pr( Other Rat = 9 | Self Rat = 1 ) =  0.000000\n",
      "\n",
      "\n",
      "Normalised Probabilities\n",
      "Pr( Self Rat = 1 | Other Rat = 1 ) =  0.000001\n",
      "Pr( Self Rat = 2 | Other Rat = 1 ) =  0.055736\n",
      "Pr( Self Rat = 3 | Other Rat = 1 ) =  0.888526\n",
      "Pr( Self Rat = 4 | Other Rat = 1 ) =  0.055736\n",
      "Pr( Self Rat = 5 | Other Rat = 1 ) =  0.000001\n",
      "Pr( Self Rat = 6 | Other Rat = 1 ) =  0.000000\n",
      "Pr( Self Rat = 7 | Other Rat = 1 ) =  0.000000\n",
      "Pr( Self Rat = 8 | Other Rat = 1 ) =  0.000000\n",
      "Pr( Self Rat = 9 | Other Rat = 1 ) =  0.000000\n"
     ]
    }
   ],
   "source": [
    "Ndim = 99 \n",
    "base = 11 \n",
    "t = 1\n",
    "rating_s = 1\n",
    "rating_o = 1\n",
    "\n",
    "alpha_s = 4.5975\n",
    "alpha_o = 4.5975\n",
    "beta_s = 14.5725\n",
    "beta_o = 14.5725\n",
    "\n",
    "order = 1 # self first, then other\n",
    "run_experiment(Ndim, base, alpha_s, alpha_o, beta_s, beta_o, t, rating_s, order)\n",
    "print(\"\\n\")\n",
    "order = 2 # other first, then self\n",
    "run_experiment(Ndim, base, alpha_s, alpha_o, beta_s, beta_o, t, rating_o, order)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6260509064eb67b36916815bc82da85b0a66bf2dbc63b7ed396e364365f7498b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
